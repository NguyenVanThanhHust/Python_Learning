{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Region Of Interest Pooling.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "kNlqZZwFDvYk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "outputId": "1e02fb57-0c11-4b13-b7e3-702e22ca5ac7"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Layer\n",
        "\n",
        "# This is a test to implement Region of Interest Pooling\n",
        "\"\"\"\n",
        "Input is two tensors:\n",
        "- A batch of images: all images must have the same shape resulting shape\n",
        "of the tensorf will be (batch_size, img_width img_height, n_channels)\n",
        "- A batch of Region of Interest proposals: shape of this tensor will be (batch_size, n_rois, 4)\n",
        "\n",
        "Output:\n",
        "List of embedding for each image, shape of outputs is (batch_size, num_rois, pool_width, pool_height, n_channels)\n",
        "\"\"\"\n",
        "\n",
        "from tensorflow.keras.layers import Layer\n",
        "class ROIPoolingLayer(Layer):\n",
        "  def __init__(self, pooled_width, pooled_height, **kwargs):\n",
        "    self.pooled_height = pooled_height\n",
        "    self.pooled_width = pooled_width\n",
        "    super(ROIPoolingLayer, self).__init__(**kwargs)\n",
        "  \n",
        "  def comput_output_shape(self, input_shape):\n",
        "    \"\"\"\n",
        "    Return the shape of the ROI Layer output\n",
        "    \"\"\"\n",
        "    feature_map_shape, rois_shape = input_shape\n",
        "    assert feature_map_shape[0] == input_shape[0] # batch size must be the same\n",
        "    batch_size = feature_map_shape\n",
        "    num_rois = rois_shape[1]\n",
        "    num_channels = feature_map_shape[3]\n",
        "    return (batch_size, num_rois, self.pooled_height, self.pooled_width, num_channels)\n",
        "\n",
        "  def call(self, x):\n",
        "    \"\"\"\n",
        "    Map the input tensorf of the ROI layer to its output\n",
        "\n",
        "    # Parameters\n",
        "      x[0] -- Convolutional feature map tensor,\n",
        "              shape (batch_size, img_width img_height, n_channels)\n",
        "      x[1] -- Tensor of region of interest from candidate bounding boxes,\n",
        "              shape (batch_size, n_rois, 4)\n",
        "\n",
        "    # Output\n",
        "      pooled_areas -- Tensor with the pooled region of interest\n",
        "      shape (batch_size, num_rois, pooled_height, pooled_width, n_channels)\n",
        "    \"\"\"\n",
        "    def curried_pool_rois(x):\n",
        "      return ROIPoolingLayer._pool_rois(x[0], x[1], \n",
        "                                        self.pooled_height, \n",
        "                                        self.pooled_width)\n",
        "    pooled_areas = tf.map_fn(curried_pool_rois, x, dtype = tf.float32)\n",
        "    return pooled_areas\n",
        "  \n",
        "  @staticmethod\n",
        "  def _pool_rois(feature_map, rois, pooled_height, pooled_width):\n",
        "    \"\"\"\n",
        "    Apply ROI pooling to a single image and many region of interest\n",
        "    \"\"\"\n",
        "    def curried_pool_roi(roi):\n",
        "      return ROIPoolingLayer._pool_roi(feature_map, roi, pooled_height, pooled_width)\n",
        "\n",
        "    # Use default tensorflow map_fn to map function to each element in rois\n",
        "    pooled_ares = tf.map_fn(curried_pool_roi, rois, dtype = tf.float32)\n",
        "    return pooled_ares\n",
        "\n",
        "  @staticmethod\n",
        "  def _pool_roi(feature_map, roi, pooled_height, pooled_width):\n",
        "    \"\"\"\n",
        "    Apply ROI pooling to a single image and single region of interest\n",
        "    \"\"\"\n",
        "    # Compute the region of interest\n",
        "    feature_map_height = int(feature_map.shape[0])\n",
        "    feature_map_width = int(feature_map.shape[1])\n",
        "\n",
        "    h_start = tf.cast(feature_map_height * roi[0], 'int32')\n",
        "    w_start = tf.cast(feature_map_width  * roi[1], 'int32')\n",
        "    h_end   = tf.cast(feature_map_height * roi[2], 'int32')\n",
        "    w_end   = tf.cast(feature_map_width  * roi[3], 'int32')\n",
        "\n",
        "    region = feature_map[h_start: h_end, w_start: w_end]\n",
        "\n",
        "    # Divide the region into non overlapping areas\n",
        "    region_height = h_end - h_start\n",
        "    region_width = w_end - w_start\n",
        "\n",
        "    h_step = tf.cast(region_height / pooled_height, 'int32')\n",
        "    w_step = tf.cast(region_width / pooled_width, 'int32')\n",
        "\n",
        "    # for i in range(pooled_height):\n",
        "    #   for j in range(pooled_width):\n",
        "    areas = [[(i* h_step, \n",
        "               j* w_step,\n",
        "               (j + 1)*h_step if i+1 < pooled_height else region_height, \n",
        "               (j + 1)*w_step if j+1 < pooled_width else region_width\n",
        "               )\n",
        "              for j in range(pooled_width)]\n",
        "             for i in range(pooled_height)]\n",
        "    # take the maximum of each area and stack the result\n",
        "    def pool_area(x):\n",
        "      return tf.math.reduce_max(region[x[0]:x[2], x[1]:x[3], :], axis = [0, 1])\n",
        "\n",
        "    pooled_features = tf.stack([[pool_area(x) for x in row] for row in areas])\n",
        "    return pooled_features  "
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xluob1gXEEf1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "fd53da6e-a952-4287-8843-8cefcec08049"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# Define parameters\n",
        "batch_size = 1\n",
        "img_height = 4\n",
        "img_width = 6\n",
        "num_channel = 1\n",
        "num_roi = 2\n",
        "pooled_width = 2\n",
        "pooled_height = 2\n",
        "\n",
        "# Create feature map input\n",
        "feature_map_shape = (batch_size, img_height, img_width, num_channel)\n",
        "feature_map_tf = tf.placeholder(tf.float32, shape = feature_map_shape)\n",
        "\n",
        "feature_map_np = np.asarray([[[[88],[44],[14],[16],[13],[96]],\n",
        "                     [[61],[63],[15],[120],[66],[15]],\n",
        "                      [[7],[4],[93],[11],[57],[88]],\n",
        "                      [[33],[47],[21],[111],[5],[6]]]], dtype = 'float32')\n",
        "# feature_map_np = np.asarray([[[88,44,14,16,13,96],\n",
        "#                      [61,63,15,120,66,15],\n",
        "#                       [7,4,93,11,57,88],\n",
        "#                       [33,47,21,111,5,6]]], dtype = 'float32')\n",
        "print(f\"feature_map_np shape = {feature_map_np.shape}\")\n",
        "\n",
        "# Create Batch size\n",
        "roi_tf = tf.placeholder(tf.float32, shape = (batch_size, num_roi, 4))\n",
        "\n",
        "x_start_1, y_start_1, width_1, height_1 = 0.0, 0.0, 3.0, 3.0\n",
        "x_start_2, y_start_2, width_2, height_2 = 0.0, 0.0, 6.0, 6.0\n",
        "\n",
        "roi_np = np.asarray([[[0.0, 0.0, 0.5, 0.5], \n",
        "                     [0.0, 0.0, 1.0, 1.0]]], dtype = 'float32')\n",
        "print(\"Roi shape = \", roi_np.shape)\n",
        "\n",
        "# Create layer \n",
        "roi_layer = ROIPoolingLayer(pooled_height, pooled_width)\n",
        "pooled_features = roi_layer([feature_map_tf, roi_tf])\n",
        "print(\"Output feature shape: \", pooled_features.shape)\n",
        "\n",
        "# Run tensorflow session\n",
        "with tf.Session() as sess:\n",
        "  result = sess.run(pooled_features, \n",
        "                    feed_dict = {feature_map_tf: feature_map_np,\n",
        "                                 roi_tf:roi_np})\n",
        "  print(\"Result shape: \", result.shape)\n",
        "  print(\"First roi embedding = \",result[0,0,:,:,0] )\n",
        "  print(\"Second roi embedding = \",result[0,1,:,:,0] )"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "feature_map_np shape = (1, 4, 6, 1)\n",
            "Roi shape =  (1, 2, 4)\n",
            "Output feature shape:  (1, 2, 2, 2, 1)\n",
            "Result shape:  (1, 2, 2, 2, 1)\n",
            "First roi embedding =  [[88. 63.]\n",
            " [61. 63.]]\n",
            "Second roi embedding =  [[ 88. 120.]\n",
            " [ 93. 111.]]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}