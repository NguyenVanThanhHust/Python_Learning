{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Fast Gradient Sign Attack.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "LWHAblis9A1G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import print_function\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vtzp4qml-UkK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "ea3626d6-2ed6-49b3-edbf-ab0123477e4f"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lQHtgUuK-adL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d367f523-773e-482b-a838-c6bd02934b45"
      },
      "source": [
        "with open('/content/drive/My Drive/foo.txt', 'w') as f:\n",
        "  f.write('Hello Google Drive!')\n",
        "!cat /content/drive/My\\ Drive/foo.txt"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Hello Google Drive!"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RzGVdvHL9Pxx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "epsilons = [0, .05, .1, .15, .2, .25, .3]\n",
        "pretrained_model = \"/content/drive/My Drive/data/lenet_mnist_model.pth\"\n",
        "use_cuda=True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PmQrXbgR-Dpl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ab32d03c-e1fa-4afa-9b09-995e438b8939"
      },
      "source": [
        "import os\n",
        "if os.path.isfile(pretrained_model):\n",
        "  print(\"ok\")"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ok\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V7tFGdhT-n8_",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mBfxNuSL-lzO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        },
        "outputId": "7ca3e37c-b8a6-489a-f836-701e5d25d1f1"
      },
      "source": [
        "# LeNet Model definition\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
        "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
        "        self.conv2_drop = nn.Dropout2d()\n",
        "        self.fc1 = nn.Linear(320, 50)\n",
        "        self.fc2 = nn.Linear(50, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
        "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
        "        x = x.view(-1, 320)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.dropout(x, training=self.training)\n",
        "        x = self.fc2(x)\n",
        "        return F.log_softmax(x, dim=1)\n",
        "\n",
        "# MNIST Test dataset and dataloader declaration\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    datasets.MNIST('../data', train=False, download=True, transform=transforms.Compose([\n",
        "            transforms.ToTensor(),\n",
        "            ])),\n",
        "        batch_size=1, shuffle=True)\n",
        "\n",
        "# Define what device we are using\n",
        "print(\"CUDA Available: \",torch.cuda.is_available())\n",
        "device = torch.device(\"cuda\" if (use_cuda and torch.cuda.is_available()) else \"cpu\")\n",
        "\n",
        "# Initialize the network\n",
        "model = Net().to(device)\n",
        "\n",
        "# Load the pretrained model\n",
        "model.load_state_dict(torch.load(pretrained_model, map_location='cpu'))\n",
        "\n",
        "# Set the model in evaluation mode. In this case this is for the Dropout layers\n",
        "model.eval()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 0/9912422 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ../data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "9920512it [00:00, 21714972.06it/s]                            \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ../data/MNIST/raw/train-images-idx3-ubyte.gz to ../data/MNIST/raw\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "32768it [00:00, 337267.71it/s]\n",
            "0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ../data/MNIST/raw/train-labels-idx1-ubyte.gz\n",
            "Extracting ../data/MNIST/raw/train-labels-idx1-ubyte.gz to ../data/MNIST/raw\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ../data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1654784it [00:00, 6277607.42it/s]                           \n",
            "8192it [00:00, 132293.78it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ../data/MNIST/raw/t10k-images-idx3-ubyte.gz to ../data/MNIST/raw\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ../data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n",
            "Extracting ../data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ../data/MNIST/raw\n",
            "Processing...\n",
            "Done!\n",
            "CUDA Available:  False\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Net(\n",
              "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
              "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
              "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
              "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
              "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RfWTBi5z_ZI7",
        "colab_type": "text"
      },
      "source": [
        "We define the function that creates the adversarial examples by perturbing the original inputs. The ```fgsm_attack``` function takes 3 inputs: image is the original clean image, epsilon is the pixel-wise perturbation amount."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kKEGe0jx_SZi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# FGSM attack code\n",
        "def fgsm_attack(image, epsilon, data_grad):\n",
        "  # Collect the element-wise sign of the data gradient\n",
        "  sign_data_grad = data_grad.sign()\n",
        "  # Create the perturbed image by adjusting each pixel of the input image\n",
        "  pertubed_image = image + epsilon*sign_data_grad\n",
        "  # Adding clipping to maintain [0,1] range\n",
        "  perturbed_image = torch.clamp(pertubed_image, 0, 1)\n",
        "  return pertubed_image "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yzDV9iokBOCM",
        "colab_type": "text"
      },
      "source": [
        "Each call to below test function performs a full test step on the MNIST test set and reports a final accuracy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Lf2C_1ZBDQI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test(model, device, test_loader, epsilon):\n",
        "  # Accuracy counter\n",
        "  correct = 0\n",
        "  adv_examples = []\n",
        "\n",
        "  # Loop over all examples in test set\n",
        "  for data, target in test_loader:\n",
        "    # send tha data and label to the device\n",
        "    data, target = data.to(device), target.to(device)\n",
        "\n",
        "    # Set requires_grad attributed of tensor. Important for Attack\n",
        "    data.requires_grad = True\n",
        "    \n",
        "    # Forward pass the data through the model\n",
        "    output = model(data)\n",
        "    # get the index of the max log-probability\n",
        "    init_pred = output.max(1, keepdim = True)[1]\n",
        "\n",
        "    # If the initial prediction is wrong, don't bother attacking, just move on\n",
        "    if init_pred.item() != target.item():\n",
        "      continue\n",
        "\n",
        "    # Calculate the loss\n",
        "    loss = F.nll_loss(output, target)\n",
        "    \n",
        "    # Zero all existing gradients\n",
        "    model.zero_grad()\n",
        "\n",
        "    # Calculate gradients of model in backward pass\n",
        "    loss.backward()\n",
        "\n",
        "    # Collect data grad\n",
        "    data_grad = data.grad.data\n",
        "\n",
        "    # Call FGSM Attack\n",
        "    perturbed_data = fgsm_attack(data, epsilon, data_grad)\n",
        "\n",
        "    # Re-classify the perturbed image\n",
        "    output = model(perturbed_data)\n",
        "\n",
        "    # Check for success\n",
        "    final_pred = output.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
        "    if final_pred.item() == target.item():\n",
        "        correct += 1\n",
        "        # Special case for saving 0 epsilon examples\n",
        "        if (epsilon == 0) and (len(adv_examples) < 5):\n",
        "            adv_ex = perturbed_data.squeeze().detach().cpu().numpy()\n",
        "            adv_examples.append( (init_pred.item(), final_pred.item(), adv_ex) )\n",
        "    else:\n",
        "        # Save some adv examples for visualization later\n",
        "        if len(adv_examples) < 5:\n",
        "            adv_ex = perturbed_data.squeeze().detach().cpu().numpy()\n",
        "            adv_examples.append( (init_pred.item(), final_pred.item(), adv_ex) )\n",
        "\n",
        "  # Calculate final accuracy for this epsilon\n",
        "  final_acc = correct/float(len(test_loader))\n",
        "  print(\"Epsilon: {}\\tTest Accuracy = {} / {} = {}\".format(epsilon, correct, len(test_loader), final_acc))\n",
        "\n",
        "  # Return the accuracy and an adversarial example\n",
        "  return final_acc, adv_examples"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nnXuqBEEJX36",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "b41778ad-8af6-49ff-9c7b-444a05ce1ce7"
      },
      "source": [
        "accuracies = []\n",
        "examples = []\n",
        "\n",
        "# Run test for each epsilon\n",
        "for eps in epsilons:\n",
        "    acc, ex = test(model, device, test_loader, eps)\n",
        "    accuracies.append(acc)\n",
        "    examples.append(ex)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epsilon: 0\tTest Accuracy = 9810 / 10000 = 0.981\n",
            "Epsilon: 0.05\tTest Accuracy = 9093 / 10000 = 0.9093\n",
            "Epsilon: 0.1\tTest Accuracy = 7301 / 10000 = 0.7301\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iHo_xfB6JkSG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.figure(figsize=(5,5))\n",
        "plt.plot(epsilons, accuracies, \"*-\")\n",
        "plt.yticks(np.arange(0, 1.1, step=0.1))\n",
        "plt.xticks(np.arange(0, .35, step=0.05))\n",
        "plt.title(\"Accuracy vs Epsilon\")\n",
        "plt.xlabel(\"Epsilon\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_GXEtiWVJ-fW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Plot several examples of adversarial samples at each epsilon\n",
        "cnt = 0\n",
        "plt.figure(figsize=(8,10))\n",
        "for i in range(len(epsilons)):\n",
        "    for j in range(len(examples[i])):\n",
        "        cnt += 1\n",
        "        plt.subplot(len(epsilons),len(examples[0]),cnt)\n",
        "        plt.xticks([], [])\n",
        "        plt.yticks([], [])\n",
        "        if j == 0:\n",
        "            plt.ylabel(\"Eps: {}\".format(epsilons[i]), fontsize=14)\n",
        "        orig,adv,ex = examples[i][j]\n",
        "        plt.title(\"{} -> {}\".format(orig, adv))\n",
        "        plt.imshow(ex, cmap=\"gray\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ekBLq9B_J-2F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}